{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e95a22cb",
      "metadata": {},
      "source": [
        "# Final Project — IMDB Data Analysis and Wikimedia Stream Processing\n",
        "## by MANOUNI Mohammed ABDELMALEK Elias OUZAID Wacim - ING5 DATA IA \n",
        "\n",
        "In this notebook, we address the project requirements from start to finish:\n",
        "\n",
        "1. Download the IMDB datasets **using notebook cells** (no manual download except when explicitly required).\n",
        "2. Load and analyze the necessary datasets.\n",
        "3. Answer all questions, with results presented in **markdown** using formatted output.\n",
        "4. Implement a mini **stream processing** job based on the Wikimedia Events Platform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec27660",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "import time\n",
        "import sqlite3\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone, date\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4946292",
      "metadata": {},
      "source": [
        "## Data Sources\n",
        "\n",
        "We use publicly available datasets provided by IMDB.\n",
        "\n",
        "The data is obtained from:\n",
        "https://datasets.imdbws.com/\n",
        "\n",
        "The primary datasets used in this project include:\n",
        "- name.basics.tsv.gz\n",
        "- title.basics.tsv.gz\n",
        "- title.ratings.tsv.gz\n",
        "- title.crew.tsv.gz\n",
        "- title.akas.tsv.gz\n",
        "\n",
        "Most datasets are downloaded programmatically within the notebook. If a dataset\n",
        "is too large to be downloaded automatically, it is added manually and clearly\n",
        "documented.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "17cc03b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Déjà présent : data\\name.basics.tsv.gz\n",
            "✅ Déjà présent : data\\title.basics.tsv.gz\n",
            "✅ Déjà présent : data\\title.ratings.tsv.gz\n",
            "✅ Déjà présent : data\\title.crew.tsv.gz\n",
            "✅ Déjà présent : data\\title.akas.tsv.gz\n",
            "✅ Téléchargements terminés.\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "BASE_URL = \"https://datasets.imdbws.com/\"\n",
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "IMDB_FILES = [\n",
        "    # personnes\n",
        "    \"name.basics.tsv.gz\",\n",
        "    # titres + métadonnées\n",
        "    \"title.basics.tsv.gz\",\n",
        "    \"title.ratings.tsv.gz\",\n",
        "    \"title.crew.tsv.gz\",\n",
        "    \"title.akas.tsv.gz\",\n",
        "]\n",
        "\n",
        "def download_file(url: str, dest: Path, chunk_size: int = 1024 * 1024) -> None:\n",
        "    \"\"\"Télécharge un fichier en streaming avec barre de progression.\"\"\"\n",
        "    if dest.exists() and dest.stat().st_size > 0:\n",
        "        print(f\"✅ Déjà présent : {dest}\")\n",
        "        return\n",
        "\n",
        "    print(f\"⬇️ Téléchargement : {url} -> {dest}\")\n",
        "    with requests.get(url, stream=True, timeout=60) as r:\n",
        "        r.raise_for_status()\n",
        "        total = int(r.headers.get(\"Content-Length\", 0))\n",
        "        pbar = tqdm(total=total, unit=\"B\", unit_scale=True, desc=dest.name)\n",
        "        with open(dest, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "        pbar.close()\n",
        "\n",
        "for fname in IMDB_FILES:\n",
        "    download_file(BASE_URL + fname, DATA_DIR / fname)\n",
        "\n",
        "print(\"✅ Téléchargements terminés.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31af6fa9",
      "metadata": {},
      "source": [
        "## Data Loading\n",
        "\n",
        "We download and load the IMDB datasets directly within the notebook.\n",
        "\n",
        "The compressed TSV files are decompressed and parsed using pandas, ensuring that\n",
        "the entire data loading process is reproducible and does not rely on manual\n",
        "preprocessing steps unless explicitly noted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54727a97",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Chargement terminé.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nconst</th>\n",
              "      <th>primaryName</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>deathYear</th>\n",
              "      <th>primaryProfession</th>\n",
              "      <th>knownForTitles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nm0000001</td>\n",
              "      <td>Fred Astaire</td>\n",
              "      <td>1899</td>\n",
              "      <td>1987</td>\n",
              "      <td>actor,miscellaneous,producer</td>\n",
              "      <td>tt0072308,tt0050419,tt0027125,tt0025164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nm0000002</td>\n",
              "      <td>Lauren Bacall</td>\n",
              "      <td>1924</td>\n",
              "      <td>2014</td>\n",
              "      <td>actress,miscellaneous,soundtrack</td>\n",
              "      <td>tt0037382,tt0075213,tt0038355,tt0117057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nm0000003</td>\n",
              "      <td>Brigitte Bardot</td>\n",
              "      <td>1934</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>actress,music_department,producer</td>\n",
              "      <td>tt0057345,tt0049189,tt0056404,tt0054452</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      nconst      primaryName  birthYear  deathYear  \\\n",
              "0  nm0000001     Fred Astaire       1899       1987   \n",
              "1  nm0000002    Lauren Bacall       1924       2014   \n",
              "2  nm0000003  Brigitte Bardot       1934       <NA>   \n",
              "\n",
              "                   primaryProfession                           knownForTitles  \n",
              "0       actor,miscellaneous,producer  tt0072308,tt0050419,tt0027125,tt0025164  \n",
              "1   actress,miscellaneous,soundtrack  tt0037382,tt0075213,tt0038355,tt0117057  \n",
              "2  actress,music_department,producer  tt0057345,tt0049189,tt0056404,tt0054452  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tconst</th>\n",
              "      <th>titleType</th>\n",
              "      <th>primaryTitle</th>\n",
              "      <th>originalTitle</th>\n",
              "      <th>isAdult</th>\n",
              "      <th>startYear</th>\n",
              "      <th>endYear</th>\n",
              "      <th>runtimeMinutes</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0</td>\n",
              "      <td>1894</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt0000002</td>\n",
              "      <td>short</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>0</td>\n",
              "      <td>1892</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>5</td>\n",
              "      <td>Animation,Short</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt0000003</td>\n",
              "      <td>short</td>\n",
              "      <td>Poor Pierrot</td>\n",
              "      <td>Pauvre Pierrot</td>\n",
              "      <td>0</td>\n",
              "      <td>1892</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>5</td>\n",
              "      <td>Animation,Comedy,Romance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tconst titleType            primaryTitle           originalTitle  \\\n",
              "0  tt0000001     short              Carmencita              Carmencita   \n",
              "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
              "2  tt0000003     short            Poor Pierrot          Pauvre Pierrot   \n",
              "\n",
              "   isAdult  startYear  endYear  runtimeMinutes                    genres  \n",
              "0        0       1894     <NA>               1         Documentary,Short  \n",
              "1        0       1892     <NA>               5           Animation,Short  \n",
              "2        0       1892     <NA>               5  Animation,Comedy,Romance  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "NA = [r\"\\N\"]\n",
        "\n",
        "# Dtypes : on garde en string la plupart des colonnes IMDB\n",
        "name_dtypes = {\n",
        "    \"nconst\": \"string\",\n",
        "    \"primaryName\": \"string\",\n",
        "    \"birthYear\": \"Int64\",\n",
        "    \"deathYear\": \"Int64\",\n",
        "    \"primaryProfession\": \"string\",\n",
        "    \"knownForTitles\": \"string\",\n",
        "}\n",
        "\n",
        "title_basics_dtypes = {\n",
        "    \"tconst\": \"string\",\n",
        "    \"titleType\": \"string\",\n",
        "    \"primaryTitle\": \"string\",\n",
        "    \"originalTitle\": \"string\",\n",
        "    \"isAdult\": \"Int64\",\n",
        "    \"startYear\": \"Int64\",\n",
        "    \"endYear\": \"Int64\",\n",
        "    \"runtimeMinutes\": \"Int64\",\n",
        "    \"genres\": \"string\",  #  DOIT rester string (Reality-TV etc.)\n",
        "}\n",
        "\n",
        "ratings_dtypes = {\"tconst\": \"string\", \"averageRating\": \"float64\", \"numVotes\": \"Int64\"}\n",
        "crew_dtypes = {\"tconst\": \"string\", \"directors\": \"string\", \"writers\": \"string\"}\n",
        "\n",
        "akas_dtypes = {\n",
        "    \"titleId\": \"string\",\n",
        "    \"ordering\": \"Int64\",\n",
        "    \"title\": \"string\",\n",
        "    \"region\": \"string\",\n",
        "    \"language\": \"string\",\n",
        "    \"types\": \"string\",\n",
        "    \"attributes\": \"string\",\n",
        "    \"isOriginalTitle\": \"Int64\",\n",
        "}\n",
        "\n",
        "# Chargement\n",
        "name_basics = pd.read_csv(DATA_DIR / \"name.basics.tsv.gz\", sep=\"\\t\", na_values=NA, dtype=name_dtypes, compression=\"gzip\", low_memory=False)\n",
        "\n",
        "title_basics = pd.read_csv(\n",
        "    DATA_DIR / \"title.basics.tsv.gz\",\n",
        "    sep=\"\\t\",\n",
        "    na_values=NA,\n",
        "    dtype=\"string\",          # <--- TOUT en string au chargement\n",
        "    compression=\"gzip\",\n",
        "    low_memory=False,\n",
        "    on_bad_lines=\"skip\"      # <--- ignore les rares lignes cassées\n",
        ")\n",
        "\n",
        "# Conversion propre des colonnes numériques après chargement\n",
        "for col in [\"isAdult\", \"startYear\", \"endYear\", \"runtimeMinutes\"]:\n",
        "    title_basics[col] = pd.to_numeric(title_basics[col], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "title_ratings = pd.read_csv(DATA_DIR / \"title.ratings.tsv.gz\", sep=\"\\t\", na_values=NA, dtype=ratings_dtypes, compression=\"gzip\", low_memory=False)\n",
        "title_crew = pd.read_csv(DATA_DIR / \"title.crew.tsv.gz\", sep=\"\\t\", na_values=NA, dtype=crew_dtypes, compression=\"gzip\", low_memory=False)\n",
        "title_akas = None  # on le chargera en streaming (chunks) uniquement quand on en aura besoin\n",
        "\n",
        "\n",
        "print(\"✅ Chargement terminé.\")\n",
        "display(name_basics.head(3))\n",
        "display(title_basics.head(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd459e64",
      "metadata": {},
      "source": [
        "## 3) Questions — IMDB Analysis\n",
        "\n",
        "In this section, we compute all the requested answers.\n",
        "\n",
        " Important note about dates:\n",
        "- The `name.basics` file provides **birthYear** (year) and not the **day/month**.\n",
        "- Therefore, any question referring to a “date of birth” is handled at the **year** level only, since we must remain “Using only the data in the dataset”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec5a3ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DJA MANOU\\AppData\\Local\\Temp\\ipykernel_27780\\1812057643.py:90: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  .loc[movie_after_1900[\"genres\"].fillna(\"\").str.contains(r\"(^|,)Comedy(,|$)\")]\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### ✅ Réponses (calculées)\n",
              "\n",
              "1. **Total de personnes** : **14,953,819**\n",
              "2. **Année de naissance la plus ancienne** : **4**\n",
              "3. **Cette personne est née il y a** : **2021 ans** (référence = année 2025)\n",
              "4. **Date/année de naissance correcte ?** → *On ne peut pas prouver l'exactitude historique avec le dataset seul ; on vérifie seulement la cohérence interne (cf. section suivante).*\n",
              "5. **Année de naissance la plus récente** : **2025**\n",
              "6. **% de personnes sans année de naissance** : **95.58%**\n",
              "7. **Durée du plus long `short` après 1900** : **1311 minutes**\n",
              "8. **Durée du plus court `movie` après 1900** : **1 minutes**\n",
              "9. **Genres représentés (n=28)** : Action, Adult, Adventure, Animation, Biography, Comedy, Crime, Documentary, Drama, Family, Fantasy, Film-Noir, Game-Show, History, Horror, Music, Musical, Mystery, News, Reality-TV, Romance, Sci-Fi, Short, Sport, Talk-Show, Thriller, War, Western\n",
              "10. **Meilleure comédie (movie)** : **Space Melody** (`tt32752452`) — rating **10.0** / votes **6**\n",
              "11. **Réalisateur(s)** : Leonardo Thimo\n",
              "12. **Titres alternatifs (akas)** : 4 entrées (voir tableau ci‑dessous)\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Aperçu : personnes avec l'année de naissance la plus ancienne ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nconst</th>\n",
              "      <th>primaryName</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>deathYear</th>\n",
              "      <th>knownForTitles</th>\n",
              "      <th>birth_le_death</th>\n",
              "      <th>min_knownfor_startYear</th>\n",
              "      <th>age_at_first_knownfor</th>\n",
              "      <th>internally_consistent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>737944</th>\n",
              "      <td>nm0784172</td>\n",
              "      <td>Lucio Anneo Seneca</td>\n",
              "      <td>4</td>\n",
              "      <td>65</td>\n",
              "      <td>tt0043802,tt0218822,tt0049203,tt0972562</td>\n",
              "      <td>True</td>\n",
              "      <td>1951</td>\n",
              "      <td>1947</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           nconst         primaryName  birthYear  deathYear  \\\n",
              "737944  nm0784172  Lucio Anneo Seneca          4         65   \n",
              "\n",
              "                                 knownForTitles  birth_le_death  \\\n",
              "737944  tt0043802,tt0218822,tt0049203,tt0972562            True   \n",
              "\n",
              "        min_knownfor_startYear  age_at_first_knownfor  internally_consistent  \n",
              "737944                    1951                   1947                   True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Titres alternatifs (akas) du meilleur film ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titleId</th>\n",
              "      <th>ordering</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>language</th>\n",
              "      <th>types</th>\n",
              "      <th>attributes</th>\n",
              "      <th>isOriginalTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>1</td>\n",
              "      <td>Space Melody</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>original</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>2</td>\n",
              "      <td>H Melwdia Tou Diastimatos</td>\n",
              "      <td>GR</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>complete title</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>3</td>\n",
              "      <td>Leonardo Thimo's Space Melody</td>\n",
              "      <td>CA</td>\n",
              "      <td>en</td>\n",
              "      <td>imdbDisplay</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>4</td>\n",
              "      <td>Space Melody</td>\n",
              "      <td>GR</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      titleId  ordering                          title region language  \\\n",
              "0  tt32752452         1                   Space Melody   <NA>     <NA>   \n",
              "1  tt32752452         2      H Melwdia Tou Diastimatos     GR     <NA>   \n",
              "2  tt32752452         3  Leonardo Thimo's Space Melody     CA       en   \n",
              "3  tt32752452         4                   Space Melody     GR     <NA>   \n",
              "\n",
              "         types      attributes  isOriginalTitle  \n",
              "0     original            <NA>                1  \n",
              "1         <NA>  complete title                0  \n",
              "2  imdbDisplay            <NA>                0  \n",
              "3         <NA>            <NA>                0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =========================\n",
        "# Questions — IMDB\n",
        "# =========================\n",
        "\n",
        "TODAY = date.today()  # date locale de notre machine\n",
        "CURRENT_YEAR = TODAY.year\n",
        "\n",
        "def split_genres(series: pd.Series) -> set[str]:\n",
        "    out: set[str] = set()\n",
        "    for v in series.dropna():\n",
        "        for g in str(v).split(\",\"):\n",
        "            g = g.strip()\n",
        "            if g:\n",
        "                out.add(g)\n",
        "    return out\n",
        "\n",
        "# Q1) How many total people in data set?\n",
        "total_people = int(name_basics[\"nconst\"].nunique())\n",
        "\n",
        "# Q2) What is the earliest year of birth?\n",
        "earliest_birth_year = int(name_basics[\"birthYear\"].min(skipna=True))\n",
        "\n",
        "# Q3) How many years ago was this person born?\n",
        "years_ago_earliest = int(CURRENT_YEAR - earliest_birth_year)\n",
        "\n",
        "# Q4) Using only the data in the data set, determine if this date of birth correct.\n",
        "# ✅ On ne peut PAS confirmer l'exactitude \"réelle\" sans source externe.\n",
        "# ✅ On peut seulement vérifier la cohérence interne du dataset (voir markdown juste après).\n",
        "\n",
        "earliest_people = name_basics.loc[\n",
        "    name_basics[\"birthYear\"] == earliest_birth_year,\n",
        "    [\"nconst\", \"primaryName\", \"birthYear\", \"deathYear\", \"knownForTitles\"],\n",
        "].copy()\n",
        "\n",
        "# Règle 1 : birthYear <= deathYear si deathYear existe\n",
        "earliest_people[\"birth_le_death\"] = (\n",
        "    earliest_people[\"deathYear\"].isna()\n",
        "    | (earliest_people[\"birthYear\"] <= earliest_people[\"deathYear\"])\n",
        ")\n",
        "\n",
        "# Règle 2 : cohérence avec les titres \"knownForTitles\" (si présents)\n",
        "def min_knownfor_year(known):\n",
        "    if pd.isna(known):\n",
        "        return None\n",
        "\n",
        "    years = []\n",
        "\n",
        "    for tconst in known.split(\",\"):\n",
        "        rows = title_basics.loc[title_basics[\"tconst\"] == tconst, \"startYear\"]\n",
        "        if not rows.empty and pd.notna(rows.iloc[0]):\n",
        "            years.append(int(rows.iloc[0]))\n",
        "\n",
        "    return min(years) if years else None\n",
        "\n",
        "\n",
        "earliest_people[\"min_knownfor_startYear\"] = earliest_people[\"knownForTitles\"].apply(min_knownfor_year)\n",
        "earliest_people[\"age_at_first_knownfor\"] = earliest_people.apply(\n",
        "    lambda r: (int(r[\"min_knownfor_startYear\"]) - int(r[\"birthYear\"]))\n",
        "    if pd.notna(r[\"min_knownfor_startYear\"])\n",
        "    else np.nan,\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "# Seuil permissif : âge >= 5 si on a une date de knownFor\n",
        "earliest_people[\"internally_consistent\"] = earliest_people[\"birth_le_death\"] & (\n",
        "    earliest_people[\"min_knownfor_startYear\"].isna()\n",
        "    | (earliest_people[\"age_at_first_knownfor\"] >= 5)\n",
        ")\n",
        "\n",
        "# Q5) What is the most recent date/year of birth?\n",
        "most_recent_birth_year = int(name_basics[\"birthYear\"].max(skipna=True))\n",
        "\n",
        "# Q6) What percentage of the people do not have a listed date/year of birth?\n",
        "missing_birth_year_pct = float(name_basics[\"birthYear\"].isna().mean() * 100)\n",
        "\n",
        "# Q7) What is the length of the longest \"short\" after 1900?\n",
        "short_after_1900 = title_basics[(title_basics[\"titleType\"] == \"short\") & (title_basics[\"startYear\"] > 1900)]\n",
        "longest_short_runtime = int(short_after_1900[\"runtimeMinutes\"].max(skipna=True))\n",
        "\n",
        "# Q8) What is the length of the shortest \"movie\" after 1900?\n",
        "movie_after_1900 = title_basics[(title_basics[\"titleType\"] == \"movie\") & (title_basics[\"startYear\"] > 1900)]\n",
        "shortest_movie_runtime = int(movie_after_1900[\"runtimeMinutes\"].min(skipna=True))\n",
        "\n",
        "# Q9) List of all of the genres represented.\n",
        "all_genres = sorted(split_genres(title_basics[\"genres\"]))\n",
        "\n",
        "# Q10) Highest rated comedy \"movie\" (tie -> most votes)\n",
        "comedy_movies = (\n",
        "    movie_after_1900\n",
        "    .loc[movie_after_1900[\"genres\"].fillna(\"\").str.contains(r\"(^|,)Comedy(,|$)\")]\n",
        "    .merge(title_ratings, on=\"tconst\", how=\"inner\")\n",
        ")\n",
        "\n",
        "best_comedy = comedy_movies.sort_values([\"averageRating\", \"numVotes\"], ascending=[False, False]).head(1)\n",
        "best_row = best_comedy.iloc[0]\n",
        "\n",
        "best_tconst = str(best_row[\"tconst\"])\n",
        "best_title = str(best_row[\"primaryTitle\"])\n",
        "best_rating = float(best_row[\"averageRating\"])\n",
        "best_votes = int(best_row[\"numVotes\"])\n",
        "\n",
        "# Q11) Who was the director of the movie?\n",
        "crew_row = title_crew.loc[title_crew[\"tconst\"] == best_tconst].head(1)\n",
        "director_nconsts: list[str] = []\n",
        "if len(crew_row):\n",
        "    directors_field = crew_row.iloc[0][\"directors\"]\n",
        "    if pd.notna(directors_field):\n",
        "        director_nconsts = [x.strip() for x in str(directors_field).split(\",\") if x.strip()]\n",
        "\n",
        "directors = (\n",
        "    name_basics.loc[name_basics[\"nconst\"].isin(director_nconsts), [\"nconst\", \"primaryName\"]]\n",
        "    .drop_duplicates()\n",
        "    .sort_values(\"primaryName\")\n",
        ")\n",
        "\n",
        "# Q12) Alternate titles for the movie (if any)\n",
        "# Q12) Alternate titles for the movie (if any) — chargement en chunks (évite MemoryError)\n",
        "import pandas as pd\n",
        "\n",
        "def load_akas_for_title(akas_path, target_tconst, na_values=r\"\\N\", chunksize=1_000_000):\n",
        "    usecols = [\"titleId\", \"ordering\", \"title\", \"region\", \"language\", \"types\", \"attributes\", \"isOriginalTitle\"]\n",
        "    dtypes = {\n",
        "        \"titleId\": \"string\",\n",
        "        \"ordering\": \"Int64\",\n",
        "        \"title\": \"string\",\n",
        "        \"region\": \"string\",\n",
        "        \"language\": \"string\",\n",
        "        \"types\": \"string\",\n",
        "        \"attributes\": \"string\",\n",
        "        \"isOriginalTitle\": \"Int64\",\n",
        "    }\n",
        "\n",
        "    out = []\n",
        "    for chunk in pd.read_csv(\n",
        "        akas_path,\n",
        "        sep=\"\\t\",\n",
        "        na_values=[na_values],\n",
        "        usecols=usecols,\n",
        "        dtype=dtypes,\n",
        "        compression=\"gzip\",\n",
        "        chunksize=chunksize,\n",
        "        low_memory=False,\n",
        "    ):\n",
        "        sub = chunk[chunk[\"titleId\"] == target_tconst]\n",
        "        if not sub.empty:\n",
        "            out.append(sub)\n",
        "\n",
        "    if out:\n",
        "        return pd.concat(out, ignore_index=True)\n",
        "    return pd.DataFrame(columns=usecols)\n",
        "\n",
        "akas_path = DATA_DIR / \"title.akas.tsv.gz\"\n",
        "akas_for_best = load_akas_for_title(akas_path, best_tconst).sort_values(\"ordering\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Affichage des réponses (markdown)\n",
        "# =========================\n",
        "answers = f\"\"\"### ✅ Réponses (calculées)\n",
        "\n",
        "1. **Total de personnes** : **{total_people:,}**\n",
        "2. **Année de naissance la plus ancienne** : **{earliest_birth_year}**\n",
        "3. **Cette personne est née il y a** : **{years_ago_earliest} ans** (référence = année {CURRENT_YEAR})\n",
        "4. **Date/année de naissance correcte ?** → *On ne peut pas prouver l'exactitude historique avec le dataset seul ; on vérifie seulement la cohérence interne (cf. section suivante).*\n",
        "5. **Année de naissance la plus récente** : **{most_recent_birth_year}**\n",
        "6. **% de personnes sans année de naissance** : **{missing_birth_year_pct:.2f}%**\n",
        "7. **Durée du plus long `short` après 1900** : **{longest_short_runtime} minutes**\n",
        "8. **Durée du plus court `movie` après 1900** : **{shortest_movie_runtime} minutes**\n",
        "9. **Genres représentés (n={len(all_genres)})** : {\", \".join(all_genres)}\n",
        "10. **Meilleure comédie (movie)** : **{best_title}** (`{best_tconst}`) — rating **{best_rating}** / votes **{best_votes:,}**\n",
        "11. **Réalisateur(s)** : {\", \".join(directors[\"primaryName\"].astype(str).tolist()) if len(directors) else \"Non renseigné dans title.crew\"}\n",
        "12. **Titres alternatifs (akas)** : {len(akas_for_best)} entrées (voir tableau ci‑dessous)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(answers))\n",
        "\n",
        "print(\"\\n--- Aperçu : personnes avec l'année de naissance la plus ancienne ---\")\n",
        "display(earliest_people.sort_values(\"primaryName\").head(20))\n",
        "\n",
        "print(\"\\n--- Titres alternatifs (akas) du meilleur film ---\")\n",
        "display(akas_for_best.head(50))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f767bd29",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titleId</th>\n",
              "      <th>ordering</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>language</th>\n",
              "      <th>types</th>\n",
              "      <th>attributes</th>\n",
              "      <th>isOriginalTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>1</td>\n",
              "      <td>Space Melody</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>original</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>2</td>\n",
              "      <td>H Melwdia Tou Diastimatos</td>\n",
              "      <td>GR</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>complete title</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>3</td>\n",
              "      <td>Leonardo Thimo's Space Melody</td>\n",
              "      <td>CA</td>\n",
              "      <td>en</td>\n",
              "      <td>imdbDisplay</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>4</td>\n",
              "      <td>Space Melody</td>\n",
              "      <td>GR</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      titleId  ordering                          title region language  \\\n",
              "0  tt32752452         1                   Space Melody   <NA>     <NA>   \n",
              "1  tt32752452         2      H Melwdia Tou Diastimatos     GR     <NA>   \n",
              "2  tt32752452         3  Leonardo Thimo's Space Melody     CA       en   \n",
              "3  tt32752452         4                   Space Melody     GR     <NA>   \n",
              "\n",
              "         types      attributes  isOriginalTitle  \n",
              "0     original            <NA>                1  \n",
              "1         <NA>  complete title                0  \n",
              "2  imdbDisplay            <NA>                0  \n",
              "3         <NA>            <NA>                0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nb titres alternatifs trouvés: 4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_akas_for_title(akas_path, target_tconst, na_values=r\"\\N\", chunksize=1_000_000):\n",
        "    \"\"\"\n",
        "    Charge title.akas.tsv.gz en streaming (chunks) et ne garde que les lignes du film target_tconst.\n",
        "    Évite le MemoryError en ne chargeant jamais tout le fichier en RAM.\n",
        "    \"\"\"\n",
        "    usecols = [\"titleId\", \"ordering\", \"title\", \"region\", \"language\", \"types\", \"attributes\", \"isOriginalTitle\"]\n",
        "    dtypes = {\n",
        "        \"titleId\": \"string\",\n",
        "        \"ordering\": \"Int64\",\n",
        "        \"title\": \"string\",\n",
        "        \"region\": \"string\",\n",
        "        \"language\": \"string\",\n",
        "        \"types\": \"string\",\n",
        "        \"attributes\": \"string\",\n",
        "        \"isOriginalTitle\": \"Int64\",\n",
        "    }\n",
        "\n",
        "    out = []\n",
        "    for chunk in pd.read_csv(\n",
        "        akas_path,\n",
        "        sep=\"\\t\",\n",
        "        na_values=[na_values],\n",
        "        usecols=usecols,\n",
        "        dtype=dtypes,\n",
        "        compression=\"gzip\",\n",
        "        chunksize=chunksize,\n",
        "        low_memory=False,\n",
        "    ):\n",
        "        sub = chunk[chunk[\"titleId\"] == target_tconst]\n",
        "        if not sub.empty:\n",
        "            out.append(sub)\n",
        "\n",
        "    if out:\n",
        "        return pd.concat(out, ignore_index=True)\n",
        "    else:\n",
        "        return pd.DataFrame(columns=usecols)\n",
        "\n",
        "# Exemple d'utilisation :\n",
        "best_tconst = str(best_row[\"tconst\"])  \n",
        "akas_path = DATA_DIR / \"title.akas.tsv.gz\"\n",
        "best_akas = load_akas_for_title(akas_path, best_tconst)\n",
        "\n",
        "\n",
        "display(best_akas.head(20))\n",
        "print(\"Nb titres alternatifs trouvés:\", len(best_akas))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d545bab",
      "metadata": {},
      "source": [
        "### Explanation (Reasoning) — “Using only the data in the dataset, determine if this date of birth is correct.”\n",
        "\n",
        "- The IMDB dataset only provides **birthYear** (year): it is therefore impossible to confirm the actual date of birth without consulting an external source (Wikipedia, IMDB website, etc.), which is not allowed by the requirements.\n",
        "- We therefore apply an **internal consistency check**:\n",
        "  1. If **deathYear** is available, we require **birthYear ≤ deathYear**.\n",
        "  2. If **knownForTitles** is available, we retrieve the minimum **startYear** of those titles and verify that the age at the first title is **plausible** (with a deliberately permissive threshold, e.g. ≥ 5 years).\n",
        "- If these rules are satisfied, we conclude that **the data is internally consistent within the dataset**, without claiming that it is historically accurate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "714dd03a",
      "metadata": {},
      "source": [
        "## 4) Stream Processing — Wikimedia Events Platform\n",
        "\n",
        "Objective: to track real-time events (Wikipedia edits) for **5 entities** that\n",
        "have a trackable Wikipedia page.\n",
        "\n",
        "Proposed implementation (simple, robust, and implemented end-to-end):\n",
        "- Source: SSE endpoint `https://stream.wikimedia.org/v2/stream/recentchange`\n",
        "- Filter: `page_title` ∈ set of selected pages (entities)\n",
        "- Metrics (stored in SQLite or CSV):\n",
        "  - `edits_total` per page and per time window (e.g. 1 minute)\n",
        "  - `unique_users` per page and per time window\n",
        "  - `bot_edits` per page and per time window\n",
        "- Alerting (required):\n",
        "  - example: **alert** if a specific user edits a page, OR if the size of a change exceeds a threshold\n",
        "  - alerts are routed to a separate SQLite table (or a separate CSV file)\n",
        "\n",
        " Note:\n",
        "- This section requires an internet connection at execution time.\n",
        "- For grading purposes, the instructor can run the stream for a few minutes and\n",
        "  verify that the expected files and/or tables are correctly produced.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e045b2ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Job terminé. Lignes metrics écrites/maj: 0\n",
            "Base SQLite: D:\\bigdata\\wikimedia_metrics.sqlite\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>window_start</th>\n",
              "      <th>page_title</th>\n",
              "      <th>edits_total</th>\n",
              "      <th>unique_users</th>\n",
              "      <th>bot_edits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-12-19T22:31:00+00:00</td>\n",
              "      <td>The Godfather</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                window_start     page_title  edits_total  unique_users  \\\n",
              "0  2025-12-19T22:31:00+00:00  The Godfather            1             1   \n",
              "\n",
              "   bot_edits  \n",
              "0          0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ts</th>\n",
              "      <th>page_title</th>\n",
              "      <th>user</th>\n",
              "      <th>alert_type</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [ts, page_title, user, alert_type, details]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Paramètres : 5 entités avec pages Wikipedia traçables ---\n",
        "#ENTITIES = [\"United States\", \"France\", \"Donald Trump\", \"Wikipedia\", \"Elon Musk\"]\n",
        "\n",
        "ENTITIES = [\n",
        "    best_movie_title,          # Highest rated comedy movie (from dataset)\n",
        "    best_movie_director,       # Director of the movie\n",
        "    \"Comedy film\",              # Genre (trackable concept)\n",
        "    \"Film director\",            # Abstract IMDB-related role\n",
        "    \"Academy Award for Best Picture\"  # Film-related entity\n",
        "]\n",
        "def norm_title(s: str) -> str:\n",
        "    return (s or \"\").strip().replace(\"_\", \" \").casefold()\n",
        "\n",
        "ENTITIES_NORM = {norm_title(x) for x in ENTITIES}\n",
        "\n",
        "# --- Imports ---\n",
        "from pathlib import Path\n",
        "import sqlite3, time, json\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import requests\n",
        "from requests.exceptions import ChunkedEncodingError, ReadTimeout, ConnectionError as ReqConnectionError\n",
        "\n",
        "# --- Stockage SQLite ---\n",
        "DB_PATH = Path(\"wikimedia_metrics.sqlite\")\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS metrics_minute (\n",
        "    window_start TEXT NOT NULL,\n",
        "    page_title   TEXT NOT NULL,\n",
        "    edits_total  INTEGER NOT NULL,\n",
        "    unique_users INTEGER NOT NULL,\n",
        "    bot_edits    INTEGER NOT NULL,\n",
        "    PRIMARY KEY (window_start, page_title)\n",
        ")\n",
        "\"\"\")\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS alerts (\n",
        "    ts          TEXT NOT NULL,\n",
        "    page_title  TEXT NOT NULL,\n",
        "    user        TEXT,\n",
        "    alert_type  TEXT NOT NULL,\n",
        "    details     TEXT\n",
        ")\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "\n",
        "# --- Stream reader SSE (robuste avec reconnexion) ---\n",
        "def iter_recentchange_events(reconnect_sleep: float = 2.0):\n",
        "    url = \"https://stream.wikimedia.org/v2/stream/recentchange\"\n",
        "    headers = {\n",
        "        \"Accept\": \"text/event-stream\",\n",
        "        \"User-Agent\": \"IMDB-Wikimedia-Stream-Project/1.0 (contact: ton.email@exemple.com)\",\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            with requests.get(url, headers=headers, stream=True, timeout=60) as r:\n",
        "                if r.status_code == 429:\n",
        "                    # rate limit → on attend un peu et on réessaie\n",
        "                    time.sleep(5)\n",
        "                    continue\n",
        "                r.raise_for_status()\n",
        "\n",
        "                buf = \"\"\n",
        "                for line in r.iter_lines(decode_unicode=True):\n",
        "                    if line is None:\n",
        "                        continue\n",
        "                    if line == \"\":\n",
        "                        if \"data:\" in buf:\n",
        "                            data_lines = [l[5:].strip() for l in buf.splitlines() if l.startswith(\"data:\")]\n",
        "                            payload = \"\\n\".join(data_lines)\n",
        "                            yield payload\n",
        "                        buf = \"\"\n",
        "                    else:\n",
        "                        buf += line + \"\\n\"\n",
        "\n",
        "        except (ChunkedEncodingError, ReadTimeout, ReqConnectionError) as e:\n",
        "            # Connexion SSE coupée → reconnexion automatique\n",
        "            time.sleep(reconnect_sleep)\n",
        "            continue\n",
        "\n",
        "def run_stream_job(\n",
        "    duration_seconds: int = 600,\n",
        "    window_seconds: int = 60,\n",
        "    alert_user: str | None = None,\n",
        "    alert_abs_size_change: int = 50_000,\n",
        "    alert_burst_edits: int = 3,\n",
        "    debug: bool = False,\n",
        "):\n",
        "    start = time.time()\n",
        "    agg = {}  # {window_start: {page_title: {edits, users_set, bot_edits}}}\n",
        "\n",
        "    def window_start(ts_unix: float) -> str:\n",
        "        w = int(ts_unix // window_seconds) * window_seconds\n",
        "        return datetime.fromtimestamp(w, tz=timezone.utc).isoformat()\n",
        "\n",
        "    for raw in iter_recentchange_events():\n",
        "        if time.time() - start > duration_seconds:\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            evt = json.loads(raw)\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "        # Filtre enwiki\n",
        "        domain = (evt.get(\"meta\") or {}).get(\"domain\")\n",
        "        if domain != \"en.wikipedia.org\":\n",
        "            continue\n",
        "\n",
        "        page = evt.get(\"title\")\n",
        "        if not page:\n",
        "            continue\n",
        "\n",
        "        if norm_title(page) not in ENTITIES_NORM:\n",
        "            if debug:\n",
        "                print(\"ENWIKI:\", page)\n",
        "            continue\n",
        "\n",
        "        ts = float(evt.get(\"timestamp\", time.time()))\n",
        "        wstart = window_start(ts)\n",
        "\n",
        "        user = evt.get(\"user\")\n",
        "        bot = bool(evt.get(\"bot\", False))\n",
        "        length = evt.get(\"length\") or {}\n",
        "        size_change = None\n",
        "        if isinstance(length, dict):\n",
        "            old = length.get(\"old\")\n",
        "            new = length.get(\"new\")\n",
        "            if isinstance(old, int) and isinstance(new, int):\n",
        "                size_change = new - old\n",
        "\n",
        "        agg.setdefault(wstart, {}).setdefault(page, {\"edits\": 0, \"users\": set(), \"bot_edits\": 0})\n",
        "        agg[wstart][page][\"edits\"] += 1\n",
        "        if user:\n",
        "            agg[wstart][page][\"users\"].add(user)\n",
        "        if bot:\n",
        "            agg[wstart][page][\"bot_edits\"] += 1\n",
        "\n",
        "        # ALERT A: user spécifique\n",
        "        if alert_user and user == alert_user:\n",
        "            cur.execute(\n",
        "                \"INSERT INTO alerts(ts,page_title,user,alert_type,details) VALUES (?,?,?,?,?)\",\n",
        "                (datetime.fromtimestamp(ts, tz=timezone.utc).isoformat(), page, user, \"USER_EDIT\", \"User edited tracked page\")\n",
        "            )\n",
        "\n",
        "        # ALERT B: gros changement de taille\n",
        "        if size_change is not None and abs(size_change) >= alert_abs_size_change:\n",
        "            cur.execute(\n",
        "                \"INSERT INTO alerts(ts,page_title,user,alert_type,details) VALUES (?,?,?,?,?)\",\n",
        "                (datetime.fromtimestamp(ts, tz=timezone.utc).isoformat(), page, user, \"LARGE_SIZE_CHANGE\", f\"size_change={size_change}\")\n",
        "            )\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    # Flush + ALERT C (burst)\n",
        "    rows = []\n",
        "    for wstart, pages in agg.items():\n",
        "        for page, m in pages.items():\n",
        "            edits = int(m[\"edits\"])\n",
        "            uniq = int(len(m[\"users\"]))\n",
        "            bots = int(m[\"bot_edits\"])\n",
        "            rows.append((wstart, page, edits, uniq, bots))\n",
        "\n",
        "            if edits >= alert_burst_edits:\n",
        "                cur.execute(\n",
        "                    \"INSERT INTO alerts(ts,page_title,user,alert_type,details) VALUES (?,?,?,?,?)\",\n",
        "                    (wstart, page, None, \"BURST_EDITS\", f\"edits_in_window={edits} window_seconds={window_seconds}\")\n",
        "                )\n",
        "\n",
        "    cur.executemany(\n",
        "        \"INSERT OR REPLACE INTO metrics_minute(window_start,page_title,edits_total,unique_users,bot_edits) VALUES (?,?,?,?,?)\",\n",
        "        rows\n",
        "    )\n",
        "    conn.commit()\n",
        "\n",
        "    return len(rows)\n",
        "\n",
        "# Lancement (10 minutes)\n",
        "written = run_stream_job(duration_seconds=600, window_seconds=60, debug=False)\n",
        "print(f\"✅ Job terminé. Lignes metrics écrites/maj: {written}\")\n",
        "print(f\"Base SQLite: {DB_PATH.resolve()}\")\n",
        "\n",
        "df_metrics = pd.read_sql_query(\"SELECT * FROM metrics_minute ORDER BY window_start DESC, edits_total DESC LIMIT 50\", conn)\n",
        "df_alerts = pd.read_sql_query(\"SELECT * FROM alerts ORDER BY ts DESC LIMIT 50\", conn)\n",
        "display(df_metrics)\n",
        "display(df_alerts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "267abb00",
      "metadata": {},
      "source": [
        "## Stream Processing – Entity Selection\n",
        "\n",
        "The five tracked entities were selected directly from the IMDB dataset or are\n",
        "directly related to the movie domain:\n",
        "\n",
        "- The highest rated comedy movie identified in the dataset\n",
        "- The director of that movie\n",
        "- Film-related concepts with stable and trackable Wikipedia pages\n",
        "\n",
        "This ensures compliance with the project requirement that tracked entities\n",
        "originate from or are clearly related to the IMDB dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fd40c8",
      "metadata": {},
      "source": [
        "## 5) Notes pour le rendu (Repo Git + email)\n",
        "\n",
        "\n",
        "\n",
        "- Membres : Mohammed MANOUNI, Elias ABDELMALEK, Wacim OUZAID\n",
        "- Comment exécuter :\n",
        "  1. Avoir un noyau base anaconda ou un noyau classique jupyter + creer une cellule de code ephemere avec `pip install -r requirements.txt` puis supprimer cette cellule une fois le requirements installé\n",
        "  2. verifier que les dependances ont bien été installées\n",
        "  3. cliquer sur `Run All`\n",
        "- Fichiers attendus dans le folder du projet :\n",
        "  - `data/XXXXXXX.tsv.gz` (téléchargés automatiquement ; possibilité d’ajout manuel si problème pourquoi pas)\n",
        "  - `wikimedia_metrics.sqlite` (généré par la partie stream)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
