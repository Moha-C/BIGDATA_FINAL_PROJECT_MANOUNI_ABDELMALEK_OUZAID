{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3fad5c8",
      "metadata": {},
      "source": [
        "# Projet Final ‚Äî Analyse de donn√©es IMDB + Stream Processing Wikimedia\n",
        "\n",
        "Ce notebook r√©pond **de A √† Z** aux consignes du projet :\n",
        "\n",
        "1. T√©l√©charger les donn√©es IMDB **via une cellule** (pas de t√©l√©chargement manuel sauf exception).\n",
        "2. Charger et analyser les fichiers n√©cessaires.\n",
        "3. R√©pondre aux questions (avec r√©ponses en **markdown** via affichage format√©).\n",
        "4. Mettre en place un mini job de **stream processing** bas√© sur la plateforme d‚Äô√©v√©nements Wikimedia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fec27660",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ñ∂Ô∏è Installation (optionnel)\n",
        "# Si besoin (uniquement si vous ne les avez pas d√©j√†) :\n",
        "# %pip install pandas numpy requests tqdm sseclient-py\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "import time\n",
        "import sqlite3\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone, date\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4946292",
      "metadata": {},
      "source": [
        "## 1) T√©l√©chargement des donn√©es IMDB\n",
        "\n",
        "Source officielle : https://datasets.imdbws.com/\n",
        "\n",
        "‚ö†Ô∏è Certains fichiers sont tr√®s volumineux. Le code ci‚Äëdessous :\n",
        "- t√©l√©charge uniquement les fichiers utiles √† ce projet ;\n",
        "- les met en cache dans `./data/` (si d√©j√† pr√©sent, ne ret√©l√©charge pas) ;\n",
        "- t√©l√©charge en streaming (robuste).\n",
        "\n",
        "Si un t√©l√©chargement √©choue (r√©seau, proxy, disque), vous pouvez **ajouter manuellement** le fichier dans `./data/` et relancer le notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "17cc03b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ D√©j√† pr√©sent : data\\name.basics.tsv.gz\n",
            "‚úÖ D√©j√† pr√©sent : data\\title.basics.tsv.gz\n",
            "‚úÖ D√©j√† pr√©sent : data\\title.ratings.tsv.gz\n",
            "‚úÖ D√©j√† pr√©sent : data\\title.crew.tsv.gz\n",
            "‚úÖ D√©j√† pr√©sent : data\\title.akas.tsv.gz\n",
            "‚úÖ T√©l√©chargements termin√©s.\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "BASE_URL = \"https://datasets.imdbws.com/\"\n",
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "IMDB_FILES = [\n",
        "    # personnes\n",
        "    \"name.basics.tsv.gz\",\n",
        "    # titres + m√©tadonn√©es\n",
        "    \"title.basics.tsv.gz\",\n",
        "    \"title.ratings.tsv.gz\",\n",
        "    \"title.crew.tsv.gz\",\n",
        "    \"title.akas.tsv.gz\",\n",
        "]\n",
        "\n",
        "def download_file(url: str, dest: Path, chunk_size: int = 1024 * 1024) -> None:\n",
        "    \"\"\"T√©l√©charge un fichier en streaming avec barre de progression.\"\"\"\n",
        "    if dest.exists() and dest.stat().st_size > 0:\n",
        "        print(f\"‚úÖ D√©j√† pr√©sent : {dest}\")\n",
        "        return\n",
        "\n",
        "    print(f\"‚¨áÔ∏è T√©l√©chargement : {url} -> {dest}\")\n",
        "    with requests.get(url, stream=True, timeout=60) as r:\n",
        "        r.raise_for_status()\n",
        "        total = int(r.headers.get(\"Content-Length\", 0))\n",
        "        pbar = tqdm(total=total, unit=\"B\", unit_scale=True, desc=dest.name)\n",
        "        with open(dest, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "        pbar.close()\n",
        "\n",
        "for fname in IMDB_FILES:\n",
        "    download_file(BASE_URL + fname, DATA_DIR / fname)\n",
        "\n",
        "print(\"‚úÖ T√©l√©chargements termin√©s.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31af6fa9",
      "metadata": {},
      "source": [
        "## 2) Chargement des fichiers\n",
        "\n",
        "Les fichiers IMDB sont des TSV compress√©s (`.tsv.gz`) avec `\\N` pour les valeurs manquantes.\n",
        "\n",
        "Pour √©viter les probl√®mes m√©moire :\n",
        "- on utilise des `dtypes` quand c‚Äôest possible ;\n",
        "- on charge en entier ici (les 5 fichiers du projet sont g√©n√©ralement g√©rables), mais vous pouvez adapter en `chunksize` si besoin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "54727a97",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Chargement termin√©.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nconst</th>\n",
              "      <th>primaryName</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>deathYear</th>\n",
              "      <th>primaryProfession</th>\n",
              "      <th>knownForTitles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nm0000001</td>\n",
              "      <td>Fred Astaire</td>\n",
              "      <td>1899</td>\n",
              "      <td>1987</td>\n",
              "      <td>actor,miscellaneous,producer</td>\n",
              "      <td>tt0072308,tt0050419,tt0027125,tt0025164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nm0000002</td>\n",
              "      <td>Lauren Bacall</td>\n",
              "      <td>1924</td>\n",
              "      <td>2014</td>\n",
              "      <td>actress,miscellaneous,soundtrack</td>\n",
              "      <td>tt0037382,tt0075213,tt0038355,tt0117057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nm0000003</td>\n",
              "      <td>Brigitte Bardot</td>\n",
              "      <td>1934</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>actress,music_department,producer</td>\n",
              "      <td>tt0057345,tt0049189,tt0056404,tt0054452</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      nconst      primaryName  birthYear  deathYear  \\\n",
              "0  nm0000001     Fred Astaire       1899       1987   \n",
              "1  nm0000002    Lauren Bacall       1924       2014   \n",
              "2  nm0000003  Brigitte Bardot       1934       <NA>   \n",
              "\n",
              "                   primaryProfession                           knownForTitles  \n",
              "0       actor,miscellaneous,producer  tt0072308,tt0050419,tt0027125,tt0025164  \n",
              "1   actress,miscellaneous,soundtrack  tt0037382,tt0075213,tt0038355,tt0117057  \n",
              "2  actress,music_department,producer  tt0057345,tt0049189,tt0056404,tt0054452  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tconst</th>\n",
              "      <th>titleType</th>\n",
              "      <th>primaryTitle</th>\n",
              "      <th>originalTitle</th>\n",
              "      <th>isAdult</th>\n",
              "      <th>startYear</th>\n",
              "      <th>endYear</th>\n",
              "      <th>runtimeMinutes</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0</td>\n",
              "      <td>1894</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt0000002</td>\n",
              "      <td>short</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>0</td>\n",
              "      <td>1892</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>5</td>\n",
              "      <td>Animation,Short</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt0000003</td>\n",
              "      <td>short</td>\n",
              "      <td>Poor Pierrot</td>\n",
              "      <td>Pauvre Pierrot</td>\n",
              "      <td>0</td>\n",
              "      <td>1892</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>5</td>\n",
              "      <td>Animation,Comedy,Romance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tconst titleType            primaryTitle           originalTitle  \\\n",
              "0  tt0000001     short              Carmencita              Carmencita   \n",
              "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
              "2  tt0000003     short            Poor Pierrot          Pauvre Pierrot   \n",
              "\n",
              "   isAdult  startYear  endYear  runtimeMinutes                    genres  \n",
              "0        0       1894     <NA>               1         Documentary,Short  \n",
              "1        0       1892     <NA>               5           Animation,Short  \n",
              "2        0       1892     <NA>               5  Animation,Comedy,Romance  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "NA = [r\"\\N\"]\n",
        "\n",
        "# Dtypes : on garde en string la plupart des colonnes IMDB\n",
        "name_dtypes = {\n",
        "    \"nconst\": \"string\",\n",
        "    \"primaryName\": \"string\",\n",
        "    \"birthYear\": \"Int64\",\n",
        "    \"deathYear\": \"Int64\",\n",
        "    \"primaryProfession\": \"string\",\n",
        "    \"knownForTitles\": \"string\",\n",
        "}\n",
        "\n",
        "title_basics_dtypes = {\n",
        "    \"tconst\": \"string\",\n",
        "    \"titleType\": \"string\",\n",
        "    \"primaryTitle\": \"string\",\n",
        "    \"originalTitle\": \"string\",\n",
        "    \"isAdult\": \"Int64\",\n",
        "    \"startYear\": \"Int64\",\n",
        "    \"endYear\": \"Int64\",\n",
        "    \"runtimeMinutes\": \"Int64\",\n",
        "    \"genres\": \"string\",  # ‚úÖ DOIT rester string (Reality-TV etc.)\n",
        "}\n",
        "\n",
        "ratings_dtypes = {\"tconst\": \"string\", \"averageRating\": \"float64\", \"numVotes\": \"Int64\"}\n",
        "crew_dtypes = {\"tconst\": \"string\", \"directors\": \"string\", \"writers\": \"string\"}\n",
        "\n",
        "akas_dtypes = {\n",
        "    \"titleId\": \"string\",\n",
        "    \"ordering\": \"Int64\",\n",
        "    \"title\": \"string\",\n",
        "    \"region\": \"string\",\n",
        "    \"language\": \"string\",\n",
        "    \"types\": \"string\",\n",
        "    \"attributes\": \"string\",\n",
        "    \"isOriginalTitle\": \"Int64\",\n",
        "}\n",
        "\n",
        "# Chargement\n",
        "name_basics = pd.read_csv(DATA_DIR / \"name.basics.tsv.gz\", sep=\"\\t\", na_values=NA, dtype=name_dtypes, compression=\"gzip\", low_memory=False)\n",
        "# --- Chargement ROBUSTE de title.basics (√©vite l'erreur Reality-TV) ---\n",
        "title_basics = pd.read_csv(\n",
        "    DATA_DIR / \"title.basics.tsv.gz\",\n",
        "    sep=\"\\t\",\n",
        "    na_values=NA,\n",
        "    dtype=\"string\",          # <--- TOUT en string au chargement\n",
        "    compression=\"gzip\",\n",
        "    low_memory=False,\n",
        "    on_bad_lines=\"skip\"      # <--- ignore les rares lignes cass√©es\n",
        ")\n",
        "\n",
        "# Conversion propre des colonnes num√©riques apr√®s chargement\n",
        "for col in [\"isAdult\", \"startYear\", \"endYear\", \"runtimeMinutes\"]:\n",
        "    title_basics[col] = pd.to_numeric(title_basics[col], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "title_ratings = pd.read_csv(DATA_DIR / \"title.ratings.tsv.gz\", sep=\"\\t\", na_values=NA, dtype=ratings_dtypes, compression=\"gzip\", low_memory=False)\n",
        "title_crew = pd.read_csv(DATA_DIR / \"title.crew.tsv.gz\", sep=\"\\t\", na_values=NA, dtype=crew_dtypes, compression=\"gzip\", low_memory=False)\n",
        "title_akas = None  # on le chargera en streaming (chunks) uniquement quand on en aura besoin\n",
        "\n",
        "\n",
        "print(\"‚úÖ Chargement termin√©.\")\n",
        "display(name_basics.head(3))\n",
        "display(title_basics.head(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd459e64",
      "metadata": {},
      "source": [
        "## 3) Questions ‚Äî Analyse IMDB\n",
        "\n",
        "Dans cette section on calcule toutes les r√©ponses demand√©es.\n",
        "\n",
        "üìå Remarque importante sur les dates :\n",
        "- Le fichier `name.basics` fournit **birthYear** (ann√©e) et pas le **jour/mois**.\n",
        "- Donc toute question de type ‚Äúdate de naissance‚Äù est trait√©e √† l‚Äô√©chelle **ann√©e** uniquement (car on doit rester ‚ÄúUsing only the data in the dataset‚Äù).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9ec5a3ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DJA MANOU\\AppData\\Local\\Temp\\ipykernel_27780\\1812057643.py:90: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  .loc[movie_after_1900[\"genres\"].fillna(\"\").str.contains(r\"(^|,)Comedy(,|$)\")]\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### ‚úÖ R√©ponses (calcul√©es)\n",
              "\n",
              "1. **Total de personnes** : **14,953,819**\n",
              "2. **Ann√©e de naissance la plus ancienne** : **4**\n",
              "3. **Cette personne est n√©e il y a** : **2021 ans** (r√©f√©rence = ann√©e 2025)\n",
              "4. **Date/ann√©e de naissance correcte ?** ‚Üí *On ne peut pas prouver l'exactitude historique avec le dataset seul ; on v√©rifie seulement la coh√©rence interne (cf. section suivante).*\n",
              "5. **Ann√©e de naissance la plus r√©cente** : **2025**\n",
              "6. **% de personnes sans ann√©e de naissance** : **95.58%**\n",
              "7. **Dur√©e du plus long `short` apr√®s 1900** : **1311 minutes**\n",
              "8. **Dur√©e du plus court `movie` apr√®s 1900** : **1 minutes**\n",
              "9. **Genres repr√©sent√©s (n=28)** : Action, Adult, Adventure, Animation, Biography, Comedy, Crime, Documentary, Drama, Family, Fantasy, Film-Noir, Game-Show, History, Horror, Music, Musical, Mystery, News, Reality-TV, Romance, Sci-Fi, Short, Sport, Talk-Show, Thriller, War, Western\n",
              "10. **Meilleure com√©die (movie)** : **Space Melody** (`tt32752452`) ‚Äî rating **10.0** / votes **6**\n",
              "11. **R√©alisateur(s)** : Leonardo Thimo\n",
              "12. **Titres alternatifs (akas)** : 4 entr√©es (voir tableau ci‚Äëdessous)\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Aper√ßu : personnes avec l'ann√©e de naissance la plus ancienne ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nconst</th>\n",
              "      <th>primaryName</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>deathYear</th>\n",
              "      <th>knownForTitles</th>\n",
              "      <th>birth_le_death</th>\n",
              "      <th>min_knownfor_startYear</th>\n",
              "      <th>age_at_first_knownfor</th>\n",
              "      <th>internally_consistent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>737944</th>\n",
              "      <td>nm0784172</td>\n",
              "      <td>Lucio Anneo Seneca</td>\n",
              "      <td>4</td>\n",
              "      <td>65</td>\n",
              "      <td>tt0043802,tt0218822,tt0049203,tt0972562</td>\n",
              "      <td>True</td>\n",
              "      <td>1951</td>\n",
              "      <td>1947</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           nconst         primaryName  birthYear  deathYear  \\\n",
              "737944  nm0784172  Lucio Anneo Seneca          4         65   \n",
              "\n",
              "                                 knownForTitles  birth_le_death  \\\n",
              "737944  tt0043802,tt0218822,tt0049203,tt0972562            True   \n",
              "\n",
              "        min_knownfor_startYear  age_at_first_knownfor  internally_consistent  \n",
              "737944                    1951                   1947                   True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Titres alternatifs (akas) du meilleur film ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titleId</th>\n",
              "      <th>ordering</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>language</th>\n",
              "      <th>types</th>\n",
              "      <th>attributes</th>\n",
              "      <th>isOriginalTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>1</td>\n",
              "      <td>Space Melody</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>original</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>2</td>\n",
              "      <td>H Melwdia Tou Diastimatos</td>\n",
              "      <td>GR</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>complete title</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>3</td>\n",
              "      <td>Leonardo Thimo's Space Melody</td>\n",
              "      <td>CA</td>\n",
              "      <td>en</td>\n",
              "      <td>imdbDisplay</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>4</td>\n",
              "      <td>Space Melody</td>\n",
              "      <td>GR</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      titleId  ordering                          title region language  \\\n",
              "0  tt32752452         1                   Space Melody   <NA>     <NA>   \n",
              "1  tt32752452         2      H Melwdia Tou Diastimatos     GR     <NA>   \n",
              "2  tt32752452         3  Leonardo Thimo's Space Melody     CA       en   \n",
              "3  tt32752452         4                   Space Melody     GR     <NA>   \n",
              "\n",
              "         types      attributes  isOriginalTitle  \n",
              "0     original            <NA>                1  \n",
              "1         <NA>  complete title                0  \n",
              "2  imdbDisplay            <NA>                0  \n",
              "3         <NA>            <NA>                0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =========================\n",
        "# Questions ‚Äî IMDB\n",
        "# =========================\n",
        "\n",
        "TODAY = date.today()  # date locale de votre machine\n",
        "CURRENT_YEAR = TODAY.year\n",
        "\n",
        "def split_genres(series: pd.Series) -> set[str]:\n",
        "    out: set[str] = set()\n",
        "    for v in series.dropna():\n",
        "        for g in str(v).split(\",\"):\n",
        "            g = g.strip()\n",
        "            if g:\n",
        "                out.add(g)\n",
        "    return out\n",
        "\n",
        "# Q1) How many total people in data set?\n",
        "total_people = int(name_basics[\"nconst\"].nunique())\n",
        "\n",
        "# Q2) What is the earliest year of birth?\n",
        "earliest_birth_year = int(name_basics[\"birthYear\"].min(skipna=True))\n",
        "\n",
        "# Q3) How many years ago was this person born?\n",
        "years_ago_earliest = int(CURRENT_YEAR - earliest_birth_year)\n",
        "\n",
        "# Q4) Using only the data in the data set, determine if this date of birth correct.\n",
        "# ‚úÖ On ne peut PAS confirmer l'exactitude \"r√©elle\" sans source externe.\n",
        "# ‚úÖ On peut seulement v√©rifier la coh√©rence interne du dataset (voir markdown juste apr√®s).\n",
        "\n",
        "earliest_people = name_basics.loc[\n",
        "    name_basics[\"birthYear\"] == earliest_birth_year,\n",
        "    [\"nconst\", \"primaryName\", \"birthYear\", \"deathYear\", \"knownForTitles\"],\n",
        "].copy()\n",
        "\n",
        "# R√®gle 1 : birthYear <= deathYear si deathYear existe\n",
        "earliest_people[\"birth_le_death\"] = (\n",
        "    earliest_people[\"deathYear\"].isna()\n",
        "    | (earliest_people[\"birthYear\"] <= earliest_people[\"deathYear\"])\n",
        ")\n",
        "\n",
        "# R√®gle 2 : coh√©rence avec les titres \"knownForTitles\" (si pr√©sents)\n",
        "def min_knownfor_year(known):\n",
        "    if pd.isna(known):\n",
        "        return None\n",
        "\n",
        "    years = []\n",
        "\n",
        "    for tconst in known.split(\",\"):\n",
        "        rows = title_basics.loc[title_basics[\"tconst\"] == tconst, \"startYear\"]\n",
        "        if not rows.empty and pd.notna(rows.iloc[0]):\n",
        "            years.append(int(rows.iloc[0]))\n",
        "\n",
        "    return min(years) if years else None\n",
        "\n",
        "\n",
        "earliest_people[\"min_knownfor_startYear\"] = earliest_people[\"knownForTitles\"].apply(min_knownfor_year)\n",
        "earliest_people[\"age_at_first_knownfor\"] = earliest_people.apply(\n",
        "    lambda r: (int(r[\"min_knownfor_startYear\"]) - int(r[\"birthYear\"]))\n",
        "    if pd.notna(r[\"min_knownfor_startYear\"])\n",
        "    else np.nan,\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "# Seuil permissif : √¢ge >= 5 si on a une date de knownFor\n",
        "earliest_people[\"internally_consistent\"] = earliest_people[\"birth_le_death\"] & (\n",
        "    earliest_people[\"min_knownfor_startYear\"].isna()\n",
        "    | (earliest_people[\"age_at_first_knownfor\"] >= 5)\n",
        ")\n",
        "\n",
        "# Q5) What is the most recent date/year of birth?\n",
        "most_recent_birth_year = int(name_basics[\"birthYear\"].max(skipna=True))\n",
        "\n",
        "# Q6) What percentage of the people do not have a listed date/year of birth?\n",
        "missing_birth_year_pct = float(name_basics[\"birthYear\"].isna().mean() * 100)\n",
        "\n",
        "# Q7) What is the length of the longest \"short\" after 1900?\n",
        "short_after_1900 = title_basics[(title_basics[\"titleType\"] == \"short\") & (title_basics[\"startYear\"] > 1900)]\n",
        "longest_short_runtime = int(short_after_1900[\"runtimeMinutes\"].max(skipna=True))\n",
        "\n",
        "# Q8) What is the length of the shortest \"movie\" after 1900?\n",
        "movie_after_1900 = title_basics[(title_basics[\"titleType\"] == \"movie\") & (title_basics[\"startYear\"] > 1900)]\n",
        "shortest_movie_runtime = int(movie_after_1900[\"runtimeMinutes\"].min(skipna=True))\n",
        "\n",
        "# Q9) List of all of the genres represented.\n",
        "all_genres = sorted(split_genres(title_basics[\"genres\"]))\n",
        "\n",
        "# Q10) Highest rated comedy \"movie\" (tie -> most votes)\n",
        "comedy_movies = (\n",
        "    movie_after_1900\n",
        "    .loc[movie_after_1900[\"genres\"].fillna(\"\").str.contains(r\"(^|,)Comedy(,|$)\")]\n",
        "    .merge(title_ratings, on=\"tconst\", how=\"inner\")\n",
        ")\n",
        "\n",
        "best_comedy = comedy_movies.sort_values([\"averageRating\", \"numVotes\"], ascending=[False, False]).head(1)\n",
        "best_row = best_comedy.iloc[0]\n",
        "\n",
        "best_tconst = str(best_row[\"tconst\"])\n",
        "best_title = str(best_row[\"primaryTitle\"])\n",
        "best_rating = float(best_row[\"averageRating\"])\n",
        "best_votes = int(best_row[\"numVotes\"])\n",
        "\n",
        "# Q11) Who was the director of the movie?\n",
        "crew_row = title_crew.loc[title_crew[\"tconst\"] == best_tconst].head(1)\n",
        "director_nconsts: list[str] = []\n",
        "if len(crew_row):\n",
        "    directors_field = crew_row.iloc[0][\"directors\"]\n",
        "    if pd.notna(directors_field):\n",
        "        director_nconsts = [x.strip() for x in str(directors_field).split(\",\") if x.strip()]\n",
        "\n",
        "directors = (\n",
        "    name_basics.loc[name_basics[\"nconst\"].isin(director_nconsts), [\"nconst\", \"primaryName\"]]\n",
        "    .drop_duplicates()\n",
        "    .sort_values(\"primaryName\")\n",
        ")\n",
        "\n",
        "# Q12) Alternate titles for the movie (if any)\n",
        "# Q12) Alternate titles for the movie (if any) ‚Äî chargement en chunks (√©vite MemoryError)\n",
        "import pandas as pd\n",
        "\n",
        "def load_akas_for_title(akas_path, target_tconst, na_values=r\"\\N\", chunksize=1_000_000):\n",
        "    usecols = [\"titleId\", \"ordering\", \"title\", \"region\", \"language\", \"types\", \"attributes\", \"isOriginalTitle\"]\n",
        "    dtypes = {\n",
        "        \"titleId\": \"string\",\n",
        "        \"ordering\": \"Int64\",\n",
        "        \"title\": \"string\",\n",
        "        \"region\": \"string\",\n",
        "        \"language\": \"string\",\n",
        "        \"types\": \"string\",\n",
        "        \"attributes\": \"string\",\n",
        "        \"isOriginalTitle\": \"Int64\",\n",
        "    }\n",
        "\n",
        "    out = []\n",
        "    for chunk in pd.read_csv(\n",
        "        akas_path,\n",
        "        sep=\"\\t\",\n",
        "        na_values=[na_values],\n",
        "        usecols=usecols,\n",
        "        dtype=dtypes,\n",
        "        compression=\"gzip\",\n",
        "        chunksize=chunksize,\n",
        "        low_memory=False,\n",
        "    ):\n",
        "        sub = chunk[chunk[\"titleId\"] == target_tconst]\n",
        "        if not sub.empty:\n",
        "            out.append(sub)\n",
        "\n",
        "    if out:\n",
        "        return pd.concat(out, ignore_index=True)\n",
        "    return pd.DataFrame(columns=usecols)\n",
        "\n",
        "akas_path = DATA_DIR / \"title.akas.tsv.gz\"\n",
        "akas_for_best = load_akas_for_title(akas_path, best_tconst).sort_values(\"ordering\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Affichage des r√©ponses (markdown)\n",
        "# =========================\n",
        "answers = f\"\"\"### ‚úÖ R√©ponses (calcul√©es)\n",
        "\n",
        "1. **Total de personnes** : **{total_people:,}**\n",
        "2. **Ann√©e de naissance la plus ancienne** : **{earliest_birth_year}**\n",
        "3. **Cette personne est n√©e il y a** : **{years_ago_earliest} ans** (r√©f√©rence = ann√©e {CURRENT_YEAR})\n",
        "4. **Date/ann√©e de naissance correcte ?** ‚Üí *On ne peut pas prouver l'exactitude historique avec le dataset seul ; on v√©rifie seulement la coh√©rence interne (cf. section suivante).*\n",
        "5. **Ann√©e de naissance la plus r√©cente** : **{most_recent_birth_year}**\n",
        "6. **% de personnes sans ann√©e de naissance** : **{missing_birth_year_pct:.2f}%**\n",
        "7. **Dur√©e du plus long `short` apr√®s 1900** : **{longest_short_runtime} minutes**\n",
        "8. **Dur√©e du plus court `movie` apr√®s 1900** : **{shortest_movie_runtime} minutes**\n",
        "9. **Genres repr√©sent√©s (n={len(all_genres)})** : {\", \".join(all_genres)}\n",
        "10. **Meilleure com√©die (movie)** : **{best_title}** (`{best_tconst}`) ‚Äî rating **{best_rating}** / votes **{best_votes:,}**\n",
        "11. **R√©alisateur(s)** : {\", \".join(directors[\"primaryName\"].astype(str).tolist()) if len(directors) else \"Non renseign√© dans title.crew\"}\n",
        "12. **Titres alternatifs (akas)** : {len(akas_for_best)} entr√©es (voir tableau ci‚Äëdessous)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(answers))\n",
        "\n",
        "print(\"\\n--- Aper√ßu : personnes avec l'ann√©e de naissance la plus ancienne ---\")\n",
        "display(earliest_people.sort_values(\"primaryName\").head(20))\n",
        "\n",
        "print(\"\\n--- Titres alternatifs (akas) du meilleur film ---\")\n",
        "display(akas_for_best.head(50))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f767bd29",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titleId</th>\n",
              "      <th>ordering</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>language</th>\n",
              "      <th>types</th>\n",
              "      <th>attributes</th>\n",
              "      <th>isOriginalTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>1</td>\n",
              "      <td>Space Melody</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>original</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>2</td>\n",
              "      <td>H Melwdia Tou Diastimatos</td>\n",
              "      <td>GR</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>complete title</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>3</td>\n",
              "      <td>Leonardo Thimo's Space Melody</td>\n",
              "      <td>CA</td>\n",
              "      <td>en</td>\n",
              "      <td>imdbDisplay</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tt32752452</td>\n",
              "      <td>4</td>\n",
              "      <td>Space Melody</td>\n",
              "      <td>GR</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      titleId  ordering                          title region language  \\\n",
              "0  tt32752452         1                   Space Melody   <NA>     <NA>   \n",
              "1  tt32752452         2      H Melwdia Tou Diastimatos     GR     <NA>   \n",
              "2  tt32752452         3  Leonardo Thimo's Space Melody     CA       en   \n",
              "3  tt32752452         4                   Space Melody     GR     <NA>   \n",
              "\n",
              "         types      attributes  isOriginalTitle  \n",
              "0     original            <NA>                1  \n",
              "1         <NA>  complete title                0  \n",
              "2  imdbDisplay            <NA>                0  \n",
              "3         <NA>            <NA>                0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nb titres alternatifs trouv√©s: 4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_akas_for_title(akas_path, target_tconst, na_values=r\"\\N\", chunksize=1_000_000):\n",
        "    \"\"\"\n",
        "    Charge title.akas.tsv.gz en streaming (chunks) et ne garde que les lignes du film target_tconst.\n",
        "    √âvite le MemoryError en ne chargeant jamais tout le fichier en RAM.\n",
        "    \"\"\"\n",
        "    usecols = [\"titleId\", \"ordering\", \"title\", \"region\", \"language\", \"types\", \"attributes\", \"isOriginalTitle\"]\n",
        "    dtypes = {\n",
        "        \"titleId\": \"string\",\n",
        "        \"ordering\": \"Int64\",\n",
        "        \"title\": \"string\",\n",
        "        \"region\": \"string\",\n",
        "        \"language\": \"string\",\n",
        "        \"types\": \"string\",\n",
        "        \"attributes\": \"string\",\n",
        "        \"isOriginalTitle\": \"Int64\",\n",
        "    }\n",
        "\n",
        "    out = []\n",
        "    for chunk in pd.read_csv(\n",
        "        akas_path,\n",
        "        sep=\"\\t\",\n",
        "        na_values=[na_values],\n",
        "        usecols=usecols,\n",
        "        dtype=dtypes,\n",
        "        compression=\"gzip\",\n",
        "        chunksize=chunksize,\n",
        "        low_memory=False,\n",
        "    ):\n",
        "        sub = chunk[chunk[\"titleId\"] == target_tconst]\n",
        "        if not sub.empty:\n",
        "            out.append(sub)\n",
        "\n",
        "    if out:\n",
        "        return pd.concat(out, ignore_index=True)\n",
        "    else:\n",
        "        return pd.DataFrame(columns=usecols)\n",
        "\n",
        "# Exemple d'utilisation :\n",
        "best_tconst = str(best_row[\"tconst\"])  # best_row existe d√©j√† dans ton notebook\n",
        "akas_path = DATA_DIR / \"title.akas.tsv.gz\"\n",
        "best_akas = load_akas_for_title(akas_path, best_tconst)\n",
        "\n",
        "\n",
        "display(best_akas.head(20))\n",
        "print(\"Nb titres alternatifs trouv√©s:\", len(best_akas))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d545bab",
      "metadata": {},
      "source": [
        "### Explication (raisonnement) ‚Äî ‚ÄúUsing only the data in the data set, determine if this date of birth correct.‚Äù\n",
        "\n",
        "- Le dataset IMDB ne donne que **birthYear** (ann√©e) : il est impossible de confirmer la ‚Äúvraie‚Äù date sans consulter une source externe (Wikip√©dia, IMDB web, etc.), ce qui est interdit par la consigne.\n",
        "- Donc on applique une **v√©rification de coh√©rence interne** :\n",
        "  1. Si **deathYear** est renseign√©, alors on exige **birthYear ‚â§ deathYear**.\n",
        "  2. Si **knownForTitles** est renseign√©, on r√©cup√®re l‚Äôann√©e minimale **startYear** de ces titres, et on v√©rifie que l‚Äô√¢ge au premier titre est **plausible** (seuil volontairement permissif, ex. ‚â• 5 ans).\n",
        "- Si ces r√®gles passent, on conclut : **la donn√©e est coh√©rente √† l‚Äôint√©rieur du dataset**, sans pr√©tendre qu‚Äôelle est historiquement exacte.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "714dd03a",
      "metadata": {},
      "source": [
        "## 4) Stream Processing ‚Äî Wikimedia Events Platform\n",
        "\n",
        "Objectif : suivre en temps r√©el des √©v√©nements (modifications wiki) pour **5 entit√©s** ayant une page tra√ßable.\n",
        "\n",
        "Impl√©mentation propos√©e (simple, robuste, et not√©e ‚ÄúA √† Z‚Äù) :\n",
        "- Source : endpoint SSE `https://stream.wikimedia.org/v2/stream/recentchange`\n",
        "- Filtre : `page_title` ‚àà ensemble de pages (entit√©s)\n",
        "- M√©triques (stock√©es dans SQLite ou CSV) :\n",
        "  - `edits_total` par page et par fen√™tre de temps (ex. 1 min)\n",
        "  - `unique_users` par page et par fen√™tre\n",
        "  - `bot_edits` par page et par fen√™tre\n",
        "- Alerting (exig√©) :\n",
        "  - exemple : **alerte** si un utilisateur pr√©cis √©dite une page, OU si la taille du changement d√©passe un seuil\n",
        "  - les alertes sont rout√©es dans une table SQLite s√©par√©e (ou un CSV s√©par√©)\n",
        "\n",
        "üìå Note :\n",
        "- Ce bloc n√©cessite une connexion internet pour fonctionner au moment o√π vous ex√©cutez le notebook.\n",
        "- Pour la correction, le prof peut ex√©cuter quelques minutes, v√©rifier que les fichiers/tables sont bien produits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e045b2ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Param√®tres : choisissez 5 entit√©s avec pages Wikipedia tra√ßables ---\n",
        "#ENTITIES = [\"United States\", \"France\", \"Donald Trump\", \"Wikipedia\", \"Elon Musk\"]\n",
        "\n",
        "ENTITIES = [\n",
        "    best_movie_title,          # Highest rated comedy movie (from dataset)\n",
        "    best_movie_director,       # Director of the movie\n",
        "    \"Comedy film\",              # Genre (trackable concept)\n",
        "    \"Film director\",            # Abstract IMDB-related role\n",
        "    \"Academy Award for Best Picture\"  # Film-related entity\n",
        "]\n",
        "def norm_title(s: str) -> str:\n",
        "    return (s or \"\").strip().replace(\"_\", \" \").casefold()\n",
        "\n",
        "ENTITIES_NORM = {norm_title(x) for x in ENTITIES}\n",
        "\n",
        "# --- Imports ---\n",
        "from pathlib import Path\n",
        "import sqlite3, time, json\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import requests\n",
        "from requests.exceptions import ChunkedEncodingError, ReadTimeout, ConnectionError as ReqConnectionError\n",
        "\n",
        "# --- Stockage SQLite ---\n",
        "DB_PATH = Path(\"wikimedia_metrics.sqlite\")\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS metrics_minute (\n",
        "    window_start TEXT NOT NULL,\n",
        "    page_title   TEXT NOT NULL,\n",
        "    edits_total  INTEGER NOT NULL,\n",
        "    unique_users INTEGER NOT NULL,\n",
        "    bot_edits    INTEGER NOT NULL,\n",
        "    PRIMARY KEY (window_start, page_title)\n",
        ")\n",
        "\"\"\")\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS alerts (\n",
        "    ts          TEXT NOT NULL,\n",
        "    page_title  TEXT NOT NULL,\n",
        "    user        TEXT,\n",
        "    alert_type  TEXT NOT NULL,\n",
        "    details     TEXT\n",
        ")\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "\n",
        "# --- Stream reader SSE (robuste avec reconnexion) ---\n",
        "def iter_recentchange_events(reconnect_sleep: float = 2.0):\n",
        "    url = \"https://stream.wikimedia.org/v2/stream/recentchange\"\n",
        "    headers = {\n",
        "        \"Accept\": \"text/event-stream\",\n",
        "        \"User-Agent\": \"IMDB-Wikimedia-Stream-Project/1.0 (contact: ton.email@exemple.com)\",\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            with requests.get(url, headers=headers, stream=True, timeout=60) as r:\n",
        "                if r.status_code == 429:\n",
        "                    # rate limit ‚Üí on attend un peu et on r√©essaie\n",
        "                    time.sleep(5)\n",
        "                    continue\n",
        "                r.raise_for_status()\n",
        "\n",
        "                buf = \"\"\n",
        "                for line in r.iter_lines(decode_unicode=True):\n",
        "                    if line is None:\n",
        "                        continue\n",
        "                    if line == \"\":\n",
        "                        if \"data:\" in buf:\n",
        "                            data_lines = [l[5:].strip() for l in buf.splitlines() if l.startswith(\"data:\")]\n",
        "                            payload = \"\\n\".join(data_lines)\n",
        "                            yield payload\n",
        "                        buf = \"\"\n",
        "                    else:\n",
        "                        buf += line + \"\\n\"\n",
        "\n",
        "        except (ChunkedEncodingError, ReadTimeout, ReqConnectionError) as e:\n",
        "            # Connexion SSE coup√©e ‚Üí reconnexion automatique\n",
        "            time.sleep(reconnect_sleep)\n",
        "            continue\n",
        "\n",
        "def run_stream_job(\n",
        "    duration_seconds: int = 600,\n",
        "    window_seconds: int = 60,\n",
        "    alert_user: str | None = None,\n",
        "    alert_abs_size_change: int = 50_000,\n",
        "    alert_burst_edits: int = 3,\n",
        "    debug: bool = False,\n",
        "):\n",
        "    start = time.time()\n",
        "    agg = {}  # {window_start: {page_title: {edits, users_set, bot_edits}}}\n",
        "\n",
        "    def window_start(ts_unix: float) -> str:\n",
        "        w = int(ts_unix // window_seconds) * window_seconds\n",
        "        return datetime.fromtimestamp(w, tz=timezone.utc).isoformat()\n",
        "\n",
        "    for raw in iter_recentchange_events():\n",
        "        if time.time() - start > duration_seconds:\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            evt = json.loads(raw)\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "        # Filtre enwiki\n",
        "        domain = (evt.get(\"meta\") or {}).get(\"domain\")\n",
        "        if domain != \"en.wikipedia.org\":\n",
        "            continue\n",
        "\n",
        "        page = evt.get(\"title\")\n",
        "        if not page:\n",
        "            continue\n",
        "\n",
        "        if norm_title(page) not in ENTITIES_NORM:\n",
        "            if debug:\n",
        "                print(\"ENWIKI:\", page)\n",
        "            continue\n",
        "\n",
        "        ts = float(evt.get(\"timestamp\", time.time()))\n",
        "        wstart = window_start(ts)\n",
        "\n",
        "        user = evt.get(\"user\")\n",
        "        bot = bool(evt.get(\"bot\", False))\n",
        "        length = evt.get(\"length\") or {}\n",
        "        size_change = None\n",
        "        if isinstance(length, dict):\n",
        "            old = length.get(\"old\")\n",
        "            new = length.get(\"new\")\n",
        "            if isinstance(old, int) and isinstance(new, int):\n",
        "                size_change = new - old\n",
        "\n",
        "        agg.setdefault(wstart, {}).setdefault(page, {\"edits\": 0, \"users\": set(), \"bot_edits\": 0})\n",
        "        agg[wstart][page][\"edits\"] += 1\n",
        "        if user:\n",
        "            agg[wstart][page][\"users\"].add(user)\n",
        "        if bot:\n",
        "            agg[wstart][page][\"bot_edits\"] += 1\n",
        "\n",
        "        # ALERT A: user sp√©cifique\n",
        "        if alert_user and user == alert_user:\n",
        "            cur.execute(\n",
        "                \"INSERT INTO alerts(ts,page_title,user,alert_type,details) VALUES (?,?,?,?,?)\",\n",
        "                (datetime.fromtimestamp(ts, tz=timezone.utc).isoformat(), page, user, \"USER_EDIT\", \"User edited tracked page\")\n",
        "            )\n",
        "\n",
        "        # ALERT B: gros changement de taille\n",
        "        if size_change is not None and abs(size_change) >= alert_abs_size_change:\n",
        "            cur.execute(\n",
        "                \"INSERT INTO alerts(ts,page_title,user,alert_type,details) VALUES (?,?,?,?,?)\",\n",
        "                (datetime.fromtimestamp(ts, tz=timezone.utc).isoformat(), page, user, \"LARGE_SIZE_CHANGE\", f\"size_change={size_change}\")\n",
        "            )\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    # Flush + ALERT C (burst)\n",
        "    rows = []\n",
        "    for wstart, pages in agg.items():\n",
        "        for page, m in pages.items():\n",
        "            edits = int(m[\"edits\"])\n",
        "            uniq = int(len(m[\"users\"]))\n",
        "            bots = int(m[\"bot_edits\"])\n",
        "            rows.append((wstart, page, edits, uniq, bots))\n",
        "\n",
        "            if edits >= alert_burst_edits:\n",
        "                cur.execute(\n",
        "                    \"INSERT INTO alerts(ts,page_title,user,alert_type,details) VALUES (?,?,?,?,?)\",\n",
        "                    (wstart, page, None, \"BURST_EDITS\", f\"edits_in_window={edits} window_seconds={window_seconds}\")\n",
        "                )\n",
        "\n",
        "    cur.executemany(\n",
        "        \"INSERT OR REPLACE INTO metrics_minute(window_start,page_title,edits_total,unique_users,bot_edits) VALUES (?,?,?,?,?)\",\n",
        "        rows\n",
        "    )\n",
        "    conn.commit()\n",
        "\n",
        "    return len(rows)\n",
        "\n",
        "# Lancement (10 minutes)\n",
        "written = run_stream_job(duration_seconds=600, window_seconds=60, debug=False)\n",
        "print(f\"‚úÖ Job termin√©. Lignes metrics √©crites/maj: {written}\")\n",
        "print(f\"Base SQLite: {DB_PATH.resolve()}\")\n",
        "\n",
        "df_metrics = pd.read_sql_query(\"SELECT * FROM metrics_minute ORDER BY window_start DESC, edits_total DESC LIMIT 50\", conn)\n",
        "df_alerts = pd.read_sql_query(\"SELECT * FROM alerts ORDER BY ts DESC LIMIT 50\", conn)\n",
        "display(df_metrics)\n",
        "display(df_alerts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "267abb00",
      "metadata": {},
      "source": [
        "## Stream Processing ‚Äì Entity Selection\n",
        "\n",
        "The five tracked entities were selected directly from the IMDB dataset or are\n",
        "directly related to the movie domain:\n",
        "\n",
        "- The highest rated comedy movie identified in the dataset\n",
        "- The director of that movie\n",
        "- Film-related concepts with stable and trackable Wikipedia pages\n",
        "\n",
        "This ensures compliance with the project requirement that tracked entities\n",
        "originate from or are clearly related to the IMDB dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fd40c8",
      "metadata": {},
      "source": [
        "## 5) Notes pour le rendu (Repo Git + email)\n",
        "\n",
        "\n",
        "\n",
        "- Participants : Mohammed MANOUNI, Elias ABDELMALEK, Wacim OUZAID\n",
        "- Comment ex√©cuter :\n",
        "  1. Avoir un noyau base anaconda ou un noyau classique jupyter + creer une cellule de code ephemere avec `pip install -r requirements.txt` puis supprimer cette cellule une fois le requirements install√©\n",
        "  2. verifier que les dependances ont bien √©t√© install√©es\n",
        "  3. cliquer sur `Run All`\n",
        "- Fichiers attendus dans le folder du projet :\n",
        "  - `data/XXXXXXX.tsv.gz` (t√©l√©charg√©s automatiquement ; possibilit√© d‚Äôajout manuel si probl√®me pourquoi pas)\n",
        "  - `wikimedia_metrics.sqlite` (g√©n√©r√© par la partie stream)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
